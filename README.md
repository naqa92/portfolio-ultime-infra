# Cluster EKS avec Terraform

Ce projet utilise GitHub Actions pour automatiser le d√©ploiement d'une infrastructure via Terraform avec :

- Cluster EKS complet via plusieurs modules
- ArgoCD avec boostrap d'applications

---

# Pr√©-requis

- Terraform >= 1.12.0
- AWS CLI configur√©
- Repo git d√©di√© pour ArgoCD : `portfolio-ultime-config`
- Bucket S3 backend : `portfolio-ultime-infra`

```bash
aws s3api create-bucket \
  --bucket portfolio-ultime-infra \
  --region eu-west-3 \
  --create-bucket-configuration LocationConstraint=eu-west-3
```

> _Pour supprimer le bucket S3 : `aws s3 rb s3://portfolio-ultime-infra --force`_

- D√©finir les secrets du repo

| Secret                  | Description     |
| ----------------------- | --------------- |
| `AWS_ACCESS_KEY_ID`     | Cl√© d'acc√®s AWS |
| `AWS_SECRET_ACCESS_KEY` | Cl√© secr√®te AWS |

Terraform

- `allowed_ips` : Adresse IP personnelle en /32
- `external_dns_hosted_zone_arns` : Hosted Zone ID (Route53)

---

# üìÅ Structure du projet

```
portfolio-ultime-infra/
‚îú‚îÄ‚îÄ .github/workflows/
‚îÇ   ‚îî‚îÄ‚îÄ terraform.yml           # Pipeline CI/CD
‚îú‚îÄ‚îÄ terraform/
‚îÇ   ‚îú‚îÄ‚îÄ eks.tf                  # Configuration EKS
‚îÇ   ‚îú‚îÄ‚îÄ helm-charts.tf          # Charts Helm
‚îÇ   ‚îú‚îÄ‚îÄ pod-identity.tf         # Pod Identity
‚îÇ   ‚îú‚îÄ‚îÄ providers.tf            # Providers Terraform
‚îÇ   ‚îú‚îÄ‚îÄ variables.tf            # Variables
‚îÇ   ‚îú‚îÄ‚îÄ vpc.tf                  # Configuration VPC
‚îî‚îÄ‚îÄ README.md
```

---

# Cluster EKS complet

## Kubeconfig

```bash
aws eks --region eu-west-3 update-kubeconfig --name eks-cluster
```

## Backend S3

Bucket S3 `portfolio-ultime-infra` avec `use_lockfile = true` (plus besoin de DynamoDB pour le verrouillage)

![s3](images/s3.png)

## Infrastructure r√©seau (modules terraform-aws-vpc et terraform-aws-security-group)

- VPC (10.0.0.0/16) avec support DNS : Emplacement logique pour cr√©er les r√©seaux
  ‚îú‚îÄ‚îÄ Subnets priv√©s: 10.0.0.0/19, 10.0.32.0/19
  ‚îú‚îÄ‚îÄ Subnets publics: 10.0.64.0/19, 10.0.96.0/19
  ‚îî‚îÄ‚îÄ Pods: g√©r√©s par VPC CNI dans les subnets

> _Subnets multi-AZ (eu-west-3a et 3b)_

- Services K8S: 10.100.0.0/16
- NAT Gateway et Internet Gateway (cr√©ation automatique via enable_nat_gateway)
  - NAT : Permet aux instances dans les r√©seaux priv√©s d'acc√©der au r√©seau public
  - Internet : Permet au r√©seau public d'acc√©der √† Internet
- Tables de routage
  - Pour les subnets publics : Une route vers l'Internet Gateway est automatiquement ajout√©e.
  - Pour les subnets priv√©s : Une route vers le NAT Gateway est automatiquement ajout√©e.
- 3 Groupes de s√©curit√© : cluster, nodes et load balancer

![Networking](images/networking.png)

## Cluster EKS (module terraform-aws-eks)

- Version : 1.33
- Add-ons manag√©s :
  - CoreDNS
  - kube-proxy
  - vpc-cni
  - eks-pod-identity-agent
  - aws-ebs-csi-driver

![Add-ons](images/addons.png)

### Voir les sch√©mas pour addons

```bash
aws eks describe-addon-versions --addon-name kube-proxy
aws eks describe-addon-configuration --addon-name kube-proxy --addon-version v1.33.3-eksbuild.6
```

## EKS Pod Identity (module terraform-aws-eks-pod-identity)

Fonctionnement : Mapping IAM ‚ÜîÔ∏è Pod via un agent natif pour l'acc√®s aux services AWS depuis un pod (remplacement moderne de IRSA, plus besoin de g√©rer l'OIDC / trust policy)

> _Le ServiceAccount sera la cible de l‚Äôassociation IAM via le module pod-identity ‚Äî pas besoin d‚Äôannotation via EKS Pod Identity._

> _Note: L'association Pod Identity peut √™tre cr√©√©e AVANT le ServiceAccount, ce qui facilite l'automatisation. voir [doc](https://docs.aws.amazon.com/eks/latest/userguide/pod-id-association.html)_

- AWS EBS CSI Driver (sans KMS car optionnel)
- AWS Load Balancer Controller
- External DNS
- Cert Manager
- Cert Manager Sync

![Pod Identity](images/pod-identity.png)

> _Pour EBS CSI Driver, c'est g√©r√© directement dans la partie addons du module EKS_

## Composants additionnels

- AWS Load Balancer Controller (via Helm)

![ALB](images/alb.png)

### AWS Load Balancer Controller - Architecture de flux

Internet ‚Üí ALB (L7) ‚Üí Target groups (pod IPs) ‚Üí R√©seau VPC / Node ENI ‚Üí Pods

### AWS Load Balancer Controller - Values helm

- `defaultTargetType = "ip"` : Instance par d√©faut. Avec IP, Le trafic est directement rout√© vers les adresses IP des pods. La valeur IP est recommand√©e pour une meilleure int√©gration et performance avec la CNI Amazon VPC.
- `deregistration_delay = 120s` : Valeur fixe pour synchroniser la dur√©e avec `terminationGracePeriodSeconds` du pod pour √©viter les coupures de sessions pendant les d√©ploiements
- `vpcTags` : Nom du cluster pour r√©cup√©rer vpcID automatiquement

> _√† configurer c√¥t√© pod : terminationGracePeriodSeconds + ReadinessProbes_

# Bootstrap ArgoCD

- Repo git de configuration d√©di√© : `portfolio-ultime-config`
- Multi-sources utilis√©s dans les apps ArgoCD afin de r√©f√©rencer des values locales pour une chart helm distante
  > _Il faut √©viter d'utiliser multi-sources pour d'autres cas de figure_

## D√©ploiement

- Installation d'ArgoCD via chart Helm
- D√©ploiement des applications ArgoCD via la strat√©gie App-of-apps

![ArgoCD UI](images/argocd.png)

## External DNS

Gestion automatique des enregistrements DNS Route 53

Annotation de l'ingress √† ajouter pour cr√©er une entr√©e de type A automatiquement :

```yaml
external-dns.alpha.kubernetes.io/hostname: app.ndebaa.com
```

![Route53](images/route53.png)

## Cert Manager

Solver DNS-01 avec Route53 utilis√© pour une meilleure int√©gration.

Avantages par rapport au solver HTTP-01 :

- ‚úÖ Plus robuste : Pas de d√©pendance sur la r√©solution DNS interne du cluster
- ‚úÖ Simplicit√© : cert-manager v√©rifie directement via l'API Route53
- ‚úÖ Compatible avec l'infrastructure : external-dns avec permissions Route53
- ‚úÖ Wildcards support√©s si besoin
- ‚úÖ Production-ready : Solution standard pour les clusters priv√©s

### Cert Manager Sync

- **Projet** : [cert-manager-sync](https://github.com/robertlestak/cert-manager-sync)
- **Contexte** : ALB Controller n‚Äôutilise pas automatiquement les secrets TLS g√©n√©r√©s par cert-manager pour cr√©er un listener HTTPS sur l‚ÄôALB car il attend un ARN ACM (annotation `alb.ingress.kubernetes.io/certificate-arn`)
- **Fonctionnement** :
  - √âcoute les Issuers/Certificates cert-manager.
  - Cr√©e automatiquement un certificat dans ACM.
  - Synchronise l‚ÄôARN ACM dans les annotations du Secret Kubernetes.

![cert-manager-sync](images/cert-manager-sync.png)

Annotation de l'ingress √† ajouter pour transmettre un secretTemplate au Certificat auto-g√©n√©r√© :

```yaml
cert-manager.io/secret-template: |
  {"annotations": {"cert-manager-sync.lestak.sh/sync-enabled":"true", "cert-manager-sync.lestak.sh/acm-enabled":"true", "cert-manager-sync.lestak.sh/acm-region": "eu-west-1"}}
```

Certificat cert-manager :

![Certificat cert-manager](images/cert-manager.png)

Certificat ACM :

![Certificat ACM](images/acm.png)

## CNPG (PostgreSQL)

Cluster PostgreSQL pour l'application todolist via l'op√©rateur CNPG (1 primaire et 1 secondaire)

## KubeScape (Test s√©curit√©)

Outil open-source de s√©curit√© et de conformit√© pour Kubernetes qui analyse les configurations, d√©tecte les vuln√©rabilit√©s et applique les bonnes pratiques dans les clusters et les manifests.

Dashboard utilis√© : Headlamp (via plugin)

## Headlamp

Headlamp est une interface graphique moderne pour Kubernetes, facilitant la gestion et la visualisation des ressources du cluster. Dans ce projet, Headlamp est enrichi avec le plugin Kubescape, permettant d'int√©grer directement les r√©sultats d'analyse de s√©curit√© et de conformit√© dans le dashboard. Gr√¢ce √† ce plugin, il est possible de visualiser les rapports de scans Kubescape, d'identifier rapidement les vuln√©rabilit√©s et de suivre l'√©tat de conformit√© du cluster depuis une seule interface centralis√©e.

Token d'acc√®s n√©cessaire : `kubectl create token headlamp --namespace kube-system`

> [Doc in-cluster](https://headlamp.dev/docs/latest/installation/in-cluster/)\_

## secureCodeBox (DAST)

Outil d'analyse de s√©curit√© automatis√©e (DAST) : secureCodeBox est un projet OWASP qui propose une solution open source automatis√©e et √©volutive, int√©grant plusieurs scanners de s√©curit√© via une interface simple et l√©g√®re ‚Äî pour des tests de s√©curit√© continus et automatis√©s.

### Fonctionnement :

- Op√©rateur avec authentification s3 configur√©e
- Chart Helm `zap-automation-framework` install√© dans le namespace de l'application √† scanner
- Auto-Discovery avec scans automatis√©s √† chaque d√©ploiement + upload vers bucket S3.

Un scan va lancer 2 jobs :

- Job scan : Permet de g√©n√©rer zap-results.xml sur le bucket S3
- Job parse : Permet de g√©n√©rer findings.json sur le bucket S3 (format unifi√© et structur√© de zap-results.xml)

### Auto-Discovery

Pr√©-requis :

- Annotation sur le namespace demo `auto-discovery.securecodebox.io/enabled=true`
- Service nomm√© http/https pour la d√©tection automatique

Values :

- `repeatInterval` : √Ä chaque d√©ploiement (nouvelle r√©vision de l'image), le scan est d√©clench√© imm√©diatement et le compteur de 168h (7 jours) est r√©initialis√©. Si aucun d√©ploiement n'a lieu pendant 168h, le scan est d√©clench√© automatiquement √† l'expiration du d√©lai.
- `env` : Supporte le templating si besoin

> _N√©cessite un environnement d√©di√© aux tests_

> Documentation : [Auto-Discovery](https://www.securecodebox.io/docs/auto-discovery/service-auto-discovery/) / [default values](https://github.com/secureCodeBox/secureCodeBox/blob/main/auto-discovery/kubernetes/README.md)

### Test d'un scan manuel

```yaml
apiVersion: execution.securecodebox.io/v1
kind: Scan
metadata:
  name: zap-manual-test
  namespace: demo
spec:
  scanType: "zap-automation-framework"
  env:
    - name: TARGET_URL
      value: "http://todolist.demo.svc.cluster.local:5000"
  parameters:
    - "-autorun"
    - "/home/securecodebox/scb-automation/automation.yaml" # MountPath de la ConfigMap auto-g√©n√©r√©e (valeur par d√©faut)
  volumeMounts:
    - name: zap-config
      mountPath: /home/securecodebox/scb-automation/automation.yaml
      subPath: automation.yaml
  volumes:
    - name: zap-config
      configMap:
        name: zap-automation-framework-baseline-config # ConfigMap auto-g√©n√©r√©e
```

### Rapports upload√© vers bucket S3

![DAST S3](images/dast-s3.png)

### R√©sultat d'un rapport (Scanning DAST passif)

![DAST Report](images/dast-report.png)

---

# Pipeline d√©di√©e √† Terraform

## Fonctionnement du Workflow Dispatch

| Action                          | Format check | Init | Validate | Plan | Apply | Destroy |
| ------------------------------- | :----------: | :--: | :------: | :--: | :---: | :-----: |
| **Push**                        |      ‚úÖ      |  ‚úÖ  |    ‚úÖ    |  ‚úÖ  |  ‚úÖ   |   ‚ùå    |
| **Workflow dispatch - plan**    |      ‚úÖ      |  ‚úÖ  |    ‚úÖ    |  ‚úÖ  |  ‚ùå   |   ‚ùå    |
| **Workflow dispatch - apply**   |      ‚úÖ      |  ‚úÖ  |    ‚úÖ    |  ‚úÖ  |  ‚úÖ   |   ‚ùå    |
| **Workflow dispatch - destroy** |      ‚úÖ      |  ‚úÖ  |    ‚úÖ    |  ‚ùå  |  ‚ùå   |   ‚úÖ    |

---

## TODO

- Terraform :

  - Destroy : G√©rer load balancer, route53 et ACM
  - Passer d'ALB Controller √† Gateway Controller
  - Secret manager pour la synchronisation du repo `portfolio-ultime-config` en priv√©

- ArgoCD :

  - Rendered manifests pattern
  - R√©organisation du repo `portfolio-ultime-config` : structure et targetRevisions
  - D√©ploiements :
    - Argo Rollouts
    - Observabilit√© (avec Metrics server)
    - Headlamp (UI pour Kubescape) : [Int√©gration avec Cognito](https://headlamp.dev/docs/latest/installation/in-cluster/eks/) (√©quivalent de Keycloak)
    - Securecodebox (DAST) :
      - Hooks pour extraire les r√©sultats (findings) et les envoyer vers des syst√®mes externes (DefectDojo, Slack, Email, Dashboards grafana, Lambda, jobs CI...)
      - Scanning actif avec envs √©ph√©m√®res

- EKS Production ready :

  - Au moins 3 nodes
  - Au moins 3 AZ
  - Access Entries : Mapping IAM ‚ÜîÔ∏è utilisateurs Kubernetes automatis√© pour g√©rer plus finement les permissions d'acc√®s au cluster (remplacement moderne de aws-auth)
    - _actuellement `enable_cluster_creator_admin_permissions = true`_
  - Chiffrement EBS via `encryption_config` (KMS)
  - Logging control plane
  - Backups : Cluster (Velero) et Database (S3)
  - Branch Protection pour pipeline avec :
    - Distinction entre plan (PR) et apply (merge)
    - Approbation manuelle via environment production
  - CNI : Cillium
  - Auto-scaling : Auto-Scaler (simple) / Karpenter (avanc√©)
